\documentclass{article}
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}

\title{Project 1: Video Special Effects}
\author{Shivang Patel (shivang2402)}
\date{January 23, 2026}

\begin{document}

\maketitle

\begin{center}
    \textbf{GitHub Repository:} \url{https://github.com/shivang2402/Video-Effects}
\end{center}

\section{Introduction}

This project focuses on real-time video processing using C++ and the OpenCV library. The objective was to build a video effects application that captures a live stream from a webcam and applies various image processing techniques efficiently. \\

The application implements a wide range of filters, starting from basic pixel-wise operations like greyscale and sepia tone conversion, to more complex neighborhood-based operations such as Gaussian blur and Sobel edge detection.\\

A key aspect of this project was understanding performance optimization. I implemented convolution filters from scratch, comparing a naive implementation against an optimized, separable version to observe significant speed improvements. \\

Additionally, I integrated the ``Depth Anything V2'' deep learning model using the ONNX Runtime library to generate real-time depth maps. This allowed for creative effects like ``Digital Fog,'' where the visual output depends on the 3D structure of the scene. \\


The final application allows users to toggle between different effects dynamically using keyboard shortcuts, offering an interactive experience that combines classical computer vision with modern deep learning.

\section{Core Tasks}

\subsection{Basic Image Display}
The program captures frames from the video stream. Below is the original color frame and the standard greyscale conversion using OpenCV's \texttt{cvtColor} function (Rec. 601 weighting: 0.299R + 0.587G + 0.114B).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{screenshot_1769218131_0.png}
    \includegraphics[width=0.45\textwidth]{screenshot_1769218136_1.png}
    \caption{Original Video (Left) and Standard Greyscale (Right)}
\end{figure}

\subsection{ Greyscale}
I implemented a custom greyscale function using the desaturation method: $(max(R,G,B) + min(R,G,B)) / 2$. This preserves contrast differently than the luminance-weighted method used by OpenCV.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769218137_2.png}
    \caption{Alternative Greyscale (Desaturation Method)}
\end{figure}

\subsection{Sepia Tone}
The sepia filter gives the image an antique look by transforming RGB values. I also applied a simple vignetting effect (darkening corners) for artistic style.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769219001_0.png}
    \caption{Sepia Tone Filter}
\end{figure}

\subsection{5x5 Gaussian Blur}
I implemented two versions of a 5x5 Gaussian blur with the kernel $[1, 2, 4, 2, 1]$.
\begin{itemize}
    \item Version 1 (Naive): Uses a 2D kernel and \texttt{at<>} accessors.
    \item Version 2 (Optimized): Uses separable 1D filters (horizontal then vertical) and row pointers.
\end{itemize}

\textbf{Timing Results:}
\begin{itemize}
    \item Naive Implementation: \textbf{0.0979 seconds}
    \item Optimized Implementation: \textbf{0.0201 seconds}
    \item \textbf{Speedup:} $\sim$4.9x faster
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769218143_4.png}
    \caption{Blurred Image (Optimized Implementation)}
\end{figure}

\subsection{Sobel Edge Detection}
I implemented 3x3 Sobel filters using separable kernels to detect vertical (X) and horizontal (Y) edges. The magnitude image combines them ($M = \sqrt{sx^2 + sy^2}$) to show overall edge strength.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.32\textwidth]{screenshot_1769218145_5.png}
    \includegraphics[width=0.32\textwidth]{screenshot_1769218148_6.png}
    \includegraphics[width=0.32\textwidth]{screenshot_1769218150_7.png}
    \caption{Sobel X (Left), Sobel Y (Center), Gradient Magnitude (Right)}
\end{figure}

\subsection{Blur and Quantize}
This effect first blurs the image and then buckets color values into 10 levels, creating a posterized, painting-like effect.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769218151_8.png}
    \caption{Blur and Quantize Effect}
\end{figure}

\section{Face Detection}
Using OpenCV's Haar Cascade classifier (\texttt{haarcascade\_frontalface\_alt2.xml}), the system detects faces in real-time and draws a green bounding box around them.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769218153_9.png}
    \caption{Face Detection}
\end{figure}

\section{Depth Estimation (Depth Anything V2)}
I integrated the ``Depth Anything V2'' model using ONNX Runtime. The model predicts a depth map for the input frame, where lighter pixels represent closer objects and darker pixels represent further ones.

\subsection{Depth Map Visualization}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769218158_10.png}
    \caption{Real-time Depth Map Estimation}
\end{figure}

\subsection{Creative Depth Effect: Digital Fog}
Using the depth map, I implemented a generic ``Digital Fog'' effect. Objects further away (darker depth values) are blended with white color exponentially, simulating atmospheric scattering.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769218162_11.png}
    \caption{Digital Fog Effect (Fog density increases with distance)}
\end{figure}

\section{Additional Effects (Extensions)}

\subsection{Spotlight Effect}
This filter highlights faces by keeping them in color while converting the rest of the scene to greyscale. It demonstrates combination of face detection data with pixel-wise manipulation.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769218165_12.png}
    \caption{Spotlight Effect (Color face, Greyscale background)}
\end{figure}

\subsection{Neon Edges}
This artistic filter uses the gradient magnitude to identify edges. Strong edges are colored with vibrant, customized RGB values (Neon look), while non-edge areas are darkened significantly.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769218169_13.png}
    \caption{Neon Edges Effect}
\end{figure}

\subsection{Cartoon Effect}
This filter combines the ``Blur and Quantize'' effect with strong edge outlines (from Gradient Magnitude) drawn in black. It creates a comic-book style appearance.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{screenshot_1769218170_14.png}
    \caption{Cartoon Effect (Quantized colors + Black outlines)}
\end{figure}

\section{Reflection}
This project was a comprehensive introduction to computer vision engineering.
\begin{itemize}
    \item I learned the hard way that traversing images using \texttt{at()} is significantly slower than using row pointers. Debugging pointer arithmetic for the separable filter was challenging but taught me how images are laid out in memory.
    \item Seeing a 5x speedup just by algorithmic change (separable filters) rather than hardware upgrades emphasized the importance of writing efficient code.
    \item Getting ONNX Runtime to work was tricky, especially linking the libraries in the Makefile. 
    \item Beyond just math, I realized how simple operations like thresholding gradients or mixing color channels can create visually stunning artistic effects like the Neon or Cartoon filters.
\end{itemize}

\section{Acknowledgements}
\begin{itemize}
    \item  Checked OpenCV official documentation (\url{docs.opencv.org}) for \texttt{filter2D} and matrix operations, and ONNX Runtime C++ API docs for model inference.

    \item Used LLM tools (Claude/ChatGPT) to help debug specific segmentation faults in the pointer arithmetic logic and for explaining the ONNX tensor input shape requirements.
\end{itemize}

\end{document}
